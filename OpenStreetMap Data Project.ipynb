{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenStreetMap Case Study\n",
    "\n",
    "#### Map Area\n",
    "\n",
    "Cincinnati, OH, United States\n",
    "</n>\n",
    "\n",
    "(Specifically - The Neighborhood Norwood and small surrounding areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having lived near Cincinnati for the majority of my life and having worked in the Norwood area for the past two years, I thought I would like to explore the data surrounding one of the neighborhoods just north of downtown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import modules for this project\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with the data\n",
    "\n",
    "- Inconsistently used street names\n",
    "    - I.E. 'St.', 'St', and 'Str' all used for 'Street'\n",
    "    - Some streets have cardinal directions as their ending (which is actually fine)\n",
    "- Inconsistent capitalization\n",
    "    - OH, Oh and oh used for the state of Ohio.\n",
    "- Some addresses ended with a unit number\n",
    "    - I.E. '#26', 'A'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a mapping dictionary with our audit functions, we can correct these issues relatively easily.</br>\n",
    "\n",
    "Lets start by opening the data from our OSM file and creating our auditing dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Opening and saving OSM XML file for auditing and cleaning\n",
    "osm_file = open(\"map.osm\", encoding=\"utf-8\")\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creates a dictionary of expected street types\n",
    "\n",
    "expected = [\"Street\",\"Avenue\",\"Boulevard\",\"Drive\",\"Court\",\"Acres\",\"Alley\",\n",
    "            \"Place\",\"Way\",\"Circle\",\"Square\",\"Lane\",\"Road\",\"Trail\",\"Parkway\",\"Crescent\",\"Terrace\"]\n",
    "\n",
    "\n",
    "### Dictionary of mapping replacements for commonly used street abbr\n",
    "\n",
    "mapping = {\"St\": \"Street\",\"Str\": \"Street\",\"St.\": \"Street\",\n",
    "           \"Ave\": \"Avenue\", \"Ave.\": \"Avenue\",\n",
    "           \"Rd.\": \"Road\", \"Rd\": \"Road\",\n",
    "           \"Cir\": \"Circle\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'expected' dictionary is used to determine if a street name is correctly displayed in the data.  If it is, that particular way will not show up in our list of troublesome street names.</br>\n",
    "\n",
    "If it does, that's where the 'mapping' dictionary will help.  This ensures that inconsistent street names are adjusted to follow a set naming convention.</br>\n",
    "\n",
    "Items were added to these dictionaries as tests were performed to ensure a more robust and complete set of street names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Custom classes for auditing street name data\n",
    "\n",
    "street_types = defaultdict(set)\n",
    "\n",
    "def audit(osm_file):\n",
    "    \n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    return street_types\n",
    "    pprint.pprint(street_types)\n",
    "    \n",
    "# Custom class for finding odd street names  \n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "            \n",
    "# Custom class for correcting street names    \n",
    "def fix_street(osm_file):\n",
    "    street_types = audit(osm_file)\n",
    "    print(street_types)\n",
    "    for street_type, ways in street_types.items():\n",
    "        for name in ways:\n",
    "            if street_type in mapping:\n",
    "                better_name = name.replace(street_type, mapping[street_type])\n",
    "                print(name, \"=>\", better_name)\n",
    "    pprint.pprint(dict(street_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classes for finding/improving street names\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def update_street_name(name, mapping):\n",
    "    \n",
    "    name = string.capwords(name)\n",
    "    m = street_type_re.search(name)\n",
    "    \n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected and street_type in mapping:\n",
    "            name = re.sub(street_type_re, mapping[street_type], name)\n",
    "    else:\n",
    "        print(\"Odd Street Name: \" % name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creates a dictionary of tags with tag name as key and quantity of each tags as value\n",
    "\n",
    "def count_tags(osm_file):\n",
    "    tags = {}\n",
    "        \n",
    "    for event, elem in  ET.iterparse(osm_file): \n",
    "        if elem.tag in tags:\n",
    "            tags[elem.tag] += 1\n",
    "        else:\n",
    "            tags[elem.tag] = 1\n",
    "            \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pretty print tags\n",
    "\n",
    "def iter_parse():\n",
    "\n",
    "    tags = count_tags(osm_file)\n",
    "    pprint.pprint(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set, {'A': {'7703 Montgomery Road, Suite A'}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Running the audit\n",
    "\n",
    "audit(osm_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the Audit, we see that only one additional straggler was found.  A street name that has a suite.</br>\n",
    "\n",
    "I believe that this is nothing to worry about as this is a perfectly legitimate street name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 9855,\n",
      " 'nd': 49725,\n",
      " 'node': 41015,\n",
      " 'osm': 1,\n",
      " 'relation': 79,\n",
      " 'tag': 19559,\n",
      " 'way': 6553}\n"
     ]
    }
   ],
   "source": [
    "osm_file.seek(0) #takes you back to begining of the dataset\n",
    "iter_parse()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {'A': {'7703 Montgomery Road, Suite A'}})\n",
      "{'A': {'7703 Montgomery Road, Suite A'}}\n"
     ]
    }
   ],
   "source": [
    "osm_file.seek(0)#takes you back to begining of the dataset\n",
    "fix_street(osm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unicode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Desktop\\Data Wrangling (MongoDB)\\conversion-database-prep.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# sample of the map when validating.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m     \u001b[0mprocess_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOSM_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Data Wrangling (MongoDB)\\conversion-database-prep.py\u001b[0m in \u001b[0;36mprocess_map\u001b[1;34m(file_in, validate)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mway_tags_writer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnicodeDictWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mway_tags_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWAY_TAGS_FIELDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mnodes_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m         \u001b[0mnode_tags_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mways_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\csv.py\u001b[0m in \u001b[0;36mwriteheader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwriteheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dict_to_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrowdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Data Wrangling (MongoDB)\\conversion-database-prep.py\u001b[0m in \u001b[0;36mwriterow\u001b[1;34m(self, row)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         super(UnicodeDictWriter, self).writerow({\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         })\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Data Wrangling (MongoDB)\\conversion-database-prep.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         super(UnicodeDictWriter, self).writerow({\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         })\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unicode' is not defined"
     ]
    }
   ],
   "source": [
    "import cerberus\n",
    "%run conversion-database-prep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
